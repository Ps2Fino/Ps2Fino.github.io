{"pages":[{"title":"Curriculum Vitae","text":"(Not so) Short (& | But still as) Sweet Personal Statement Education EngD in Digital Media , September 2017 Compensating for Distance Compression in Virtual Audiovisual Environments University of Bath Advisors: Prof Eamonn O'Neill & Dr Michael Proulx Examiners: Prof Stephen Payne & Dr Betty Mohler PDF BSc in Computer Science , June 2012 Object Detection and Tracking in Images and Point Clouds University College Dublin GPA : 3.83/4.0 Advisor: Dr. Eleni Mangina PDF Research Interests Spatial perception within virtual worlds, multisensory perception, head mounted displays, spatial audio interaction, public experiences & installations Publications For a list of publications, see my Publications page Funding US National Academy of Medicine Healthy Longevity Global Grand Challenge , 2021 Catalyst Award £62,500 https://healthylongevitychallenge.org/winners/exploring-how-to-use-mixed-reality-and-telepresence-to-tackle-lonliness-and-reduce-feelings-of-social-isolation/ Competitive funding awarded from the UKRI 's Economics & Social Science Research Council ( ESRC ) to explore mixed reality in the context of community building interventions for tackling loneliness and reducing feelings of isolation. Cardiff University Innovation for All Fund , 2021 £23,750 Competitive funding awarded from the Higher Education Funding Council for Wales ( HEFCW ) to build ViewfindR prototype version 2.0, a virtual learning environment for teaching students in video journalism to develop their creative skills and plan for filming. Cardiff University ( HEFCW ) Global Challenges Research Fund Facilitation Grant , 2021 £1,900 Competitive funding awarded to conduct a workshop with colleagues in IIT Ropar, India, around IoT and VR in healthcare. Cardiff University Education Innovation Projects Scheme , 2020 £2,000 Competitive funding awarded to fund a bright undergraduate student to come work in my lab and develop software integrating virtual reality technology into an educational environment over the summer of 2020 Cardiff Undergraduate Research Opportunities Programme , 2020 £2,000 Competitive funding awarded to fund a bright undergraduate student to come work in my lab over the summer of 2020 Heritage Dot Bursary , 2019 £175 Awarded to present work on developing Serious Games for a Social Change at the Heritage Dot Conference at the University of Lincoln, June 2019 http://heritagedot.org/ Researcher Development Fund , 2016 £1,000 Awarded by University of Bath RDF to host a 1-day workshop on Games Research Across Academia and Industry https://www.camera.ac.uk/achievement-unlocked-03-july-2017 Public Engagement Fund , 2016 £500 Awarded by University of Bath PEF to host Bath's first ever Human Library Project http://humanlibrary.org/ Awards Recognizing Excellence Scheme , 2018 Merit Payment for Exceptional Performance Awarded by the Faculty of Science, University of Bath Best Accessible Game , 2014 Audio Defence: Zombine Arena Awarded by TIGA Distinguished Project , 2014 Reindeer & Wolves UBIComp Summer School ( UBISS ) Awarded by Prof Floyd Mueller Best Final Year Project , 2012 Object Detection in 2D and 3D Images Awarded by Deloitte Teaching Experience See my Teaching page Qualifications Professional Development Course for External Examiners Advance HE November 2021 Academic Practice & Reviewing Conferences Foundation of Digital Games 2021 Program Committee member, Games Beyond Entertainment and Game Education Info ISMAR 2020 Invited mentorship for Doctoral Consortium Info ACM CHI Proceedings of the ACM on Computer Human Interaction ACM VRCAI Proceedings of the ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry Webpage ACM IMWUT Proceedings of the ACM on Interactive, Mobile, Wearable, and Ubiquitous Technologies Journals Electronic Journal of e-Learning Academic Publishing PLOS One Public Library of Science Journal ETRI Journal Electronics and Telecommunications Research Institute International Journal of Game-Based Learning IGI Global Transactions on Parallel and Distributed Systems IEEE Invited Talks Public lecture at Wales Tech Week, June 2020 Info Keynote Speech at Audio Engineering Society , February 2015 56th Conference on Audio for Games Conference report here ( cache) Bath Spa University , October 2018 Guest Lecture on Using Git & Github for Project Management Sherborne Science Cafe , July 2018 Invited lecture on Perceptual Based Design for Virtual Reality Environments Info Cardiff University Brain Research Imaging Centre , May 2018 Invited lecture on Using $latex$ for Open Science Agenda Pint of Science , May 2018 Public Lecture on Spatial Perception in Virtual Worlds Abstract University of Bath , February 2018 Guest Lecture on Games for a purpose titled: Games (Beyond Games) Slides University of Bath , October 2017 Guest Lecture on auditory user interface design titled: Auditory Interfaces Bath Spa University , November 2016 Guest Lecture on Binaural Game Design and Development Bath College , February 2016 Careers Day for A-Level Students","tags":"pages","url":"https://ps2fino.github.io/pages/resume.html","loc":"https://ps2fino.github.io/pages/resume.html"},{"title":"Postgraduate Opportunities","text":"I am happy to work with ambitious and motivated students interested in pursuing a postgraduate research degree. When sending me applications, please include the following: A copy of your CV in PDF format. A personal statement in PDF format detailing why you want to pursue a PhD or other postgraduate opportunities with me. Your statement must be no longer than 1 side of A4 in length . I will not consider applications above this limit. 1 of the following: A research proposal no longer than 2 sides of A4 in length in PDF format OR A portfolio consisting of videos and/or mini-reports of work you've done. The portfolio must consist of no more than 4 files . It must be zipped into a single file no bigger than 10MB . Reports must be no longer than 2 sides of A4 in PDF format. If sending videos, please ensure they are compatible with VLC . Publicly viewable YouTube hosted videos are preferred. Your CV in particular should include: Previous educational experience. Previous (if any) academic publications you may have. Please include a DOI or link to an accessible PDF for each publication. Previous (if any) industrial experience you may have. In your email/letter addressed to me personally, please indicate the programme you are applying to and whether you are self funded, have secured grant funding to study in the UK , or are seeking funding. Information is available on the Cardiff website . I encourage you to read my list of publications and my own personal statement before contacting me. You may forward your complete application to me via email using the contact details on this page . Finally, please note that a complete application sent to me does not guarantee you a place on your programme of choice . There may be further requirements. Please contact the computer science PGR administrator by email: comsc-pgresearch@cs.cardiff.ac.uk .","tags":"pages","url":"https://ps2fino.github.io/pages/doctoral-supervision.html","loc":"https://ps2fino.github.io/pages/doctoral-supervision.html"},{"title":"Publications","text":"","tags":"pages","url":"https://ps2fino.github.io/pages/publications.html","loc":"https://ps2fino.github.io/pages/publications.html"},{"title":"Student Supervision","text":"A list of students I am currently supervising and those I have had the pleasure of supervising to completion. Where possible I have included their results and what they did/are doing post graduation. 2019/20 Tangible Tarot Readings: An Augmented Reality Tarot Desktop Application Melanie Goldstone ‘ Means, modes, and medians': Teaching fundamental statistics using serious games Artem Protasavytsky Evaluating Serious Games as an Alternative to Traditional Teaching Methods Isaac Rapley Pyzork: A Python Text Adventure Framework Clement Julia On the Effect of Augmented Reality Technologies on the Immersiveness of Gameplay Christopher Hughes Indoor Path Finding Application Nasser Alshahrani 2018/19 A Virtual Reality Application of the Rubber Hand Illusion Induced by Mid-Air Haptic Stimulation Anca Salagean, BSc [2]. Now PhD candidate at University of Bath Investigating the use of Serious Games to Improve Engagement with a Personal Development Plan Patrick Havard, BSc . Augmenting Musical Performance using Gestural Sensing Technology Tom Slattery, BSc. Now working at IBM Investigating Collaboration in a Multi-User Mixed Reality System for Military Strategic Planning James May, BSc. Sex Differences in the Experience of Motion Sickness in Virtual Reality: Influence of the Female Menstrual Cycle Grainne Bannigan, BSc. Now MSc candidate at University College London ( UCL ) Learning in a Non-Virtual Environment Versus a Virtual Environment: Does Embodied Agent Tutor Presence and Realism Impact Learning in Virtual Reality? Izzy Fitton, BSc [2]. Now PhD candidate at University of Bath The Effects of Visual Environment and Gamer Status on Performance and Engagement in Virtual Reality Exergaming Michael Colman, BSc [2]. Now MSc candidate at University of Bath The effect of naturalness of interfaces for audio games in increasing spatial awareness skills in people Ruchira Jayatilaka, MComp. Graduated first class; now working at TCP Lifesystems 2017/18 Modelling Visuohaptic Perception for Human-Machine Systems Interaction Yijing Li, MSc in Human Computer Interaction Measuring Immersion in Audio Games Based on the SCI Model Feiran Gao, MSc in Human Computer Interaction Investigation on Authenticity in Replicas of Museum Exhibitions Meng Hao, MSc in Human Computer Interaction [1] A VR Assisted Tangible Interface Collaboration Workstation for Urban Planning Ruowen Cheng, MSc in Human Computer Interaction A Kinect Tracking Library for QR Code Tracking Bo Xu, MSc in Human Computer Interaction 2016/17 Cross-platform binaural renderer Zhangyang Hu, MSc in Digital Entertainment [1]: Co-supervised with Dr Daniela De Angeli [2]: Intern co-supervised with Dr Michael Proulx","tags":"pages","url":"https://ps2fino.github.io/pages/supervision.html","loc":"https://ps2fino.github.io/pages/supervision.html"},{"title":"Teaching","text":"2021/22 CM1301 : Principles, Tools, and Techniques for Secure Software Engineering (Module Leader) CM2101 : Human Computer Interaction CMT206 : Human Centric Computing COMSC X SHARE Summer School 2020/21 CM1202 : Developing Quality Software (Module Leader) CM2101 : Human Computer Interaction CMT206 : Human Centric Computing 2019/20 CM1202 : Developing Quality Software CM2101 : Human Computer Interaction CMT206 : Human Centric Computing CM6321 : Emerging Technologies (Module Leader)","tags":"pages","url":"https://ps2fino.github.io/pages/teaching.html","loc":"https://ps2fino.github.io/pages/teaching.html"},{"title":"New Paper in ACM TAP !","text":"We've had a paper accepted into TAP ! Here's the abstract: Ultrasonic mid-air haptic technologies, which provide haptic feedback through airwaves produced using ultrasound, could be employed to investigate the sense of body ownership and immersion in virtual reality ( VR ) by inducing the virtual hand illusion ( VHI ). Ultrasonic mid-air haptic perception has solely been investigated for glabrous (hairless) skin, which has higher tactile sensitivity than hairy skin. In contrast, the VHI paradigm typically targets hairy skin without comparisons to glabrous skin. The aim of this paper was to investigate illusory body ownership, the applicability of ultrasonic mid-air haptics, and perceived immersion in VR using the VHI . Fifty participants viewed a virtual hand being stroked by a feather synchronously and asynchronously with the ultrasonic stimulation applied to the glabrous skin on the palmar surface and the hairy skin on the dorsal surface of their hands. Questionnaire responses revealed that synchronous stimulation induced a stronger VHI than asynchronous stimulation. In synchronous conditions, the VHI was stronger for palmar stimulation than dorsal stimulation. The ultrasonic stimulation was also perceived as more intense on the palmar surface compared to the dorsal surface. Perceived immersion was not related to illusory body ownership per se but was enhanced by the provision of synchronous stimulation. Reference Salagean, A., Hadnett-Hunter, J. E., Finnegan, D. J., de Sousa, A., Proulx, M. A Virtual Reality Application of the Rubber Hand Illusion Induced by Ultrasonic Mid-Air Haptic Stimulation ACM Transactions on Applied Perception PDF","tags":"Papers","url":"https://ps2fino.github.io/tap-aug-2021.html","loc":"https://ps2fino.github.io/tap-aug-2021.html"},{"title":"New Publication in Frontiers in Virtual Reality!","text":"We've had a paper accepted in Frontiers in Virtual Reality ! Here's the abstract: Recent years have seen a boom in Virtual, Augmented, and Mixed Reality technologies which have been widely adopted both by the consumer market and the research community. These technologies have provided researchers the ability to generate and gather data in new ways, through world building and scenario creation in every environment imagined. Although this growing interest is exciting, there is also a mounting concern about best practises and ethical dilemmas. In the literature one can already find a large quantity of papers providing guidelines and raising ethical concerns. However, ethical pitfalls continue to be overlooked. In this opinion paper, prompted by the ethics developments in Artificial Intelligence ( AI ), another area with rapid growth and adoption which has been overwhelmed by a huge number of guidelines and is still nowhere close to universal acceptance of standards, we propose that the virtual, augmented, and mixed reality research and development areas need to come together as whole; involving government, industry and science in order to define, develop and decide guidelines and strategies before we replicate the devastating consequences such as decaying trust in technology witnessed in other areas like social media. Reference Finnegan, D. J., Zoumpoulaki, A., Eslambolchilar, P. Does Mixed Reality Have a Cassandra Complex? Frontiers in Virtual Reality—Virtual Reality and Human Behaviour. DOI : 10.3389/frvir.2021.673547","tags":"Papers","url":"https://ps2fino.github.io/cassandra-complex.html","loc":"https://ps2fino.github.io/cassandra-complex.html"},{"title":"New Paper at INTERACT 2021!","text":"We've had a paper accepted into INTERACT 2021! Here's the abstract: Accessibility in sports media broadcast ( SMB ) remains a problem for blind spectators who wish to socialize and watch sports with friends and family. Although popular, radio's reliance on low bandwidth speech results in an overwhelming experience for blind spectators. In this paper we focused on two core issues: (i) how SMB can be augmented to convey diegetic information more effectively, and (ii) the social context in which SMB are consumed. We chose tennis broadcasts for our investigations. Addressing issue (i), we developed a system design and prototype to enhance the experience of watching tennis matches, focusing on blind spectators using audio descriptions and 3D audio, and evaluated our system with (n=12) in a controlled user evaluation. Our results indicate how audio descriptions gave clear information for the tennis ball placements, 3D audio provided subtle cues for the ball direction, and radio provided desired human commentary. For issue (ii), we conducted an online questionnaire (n=15) investigating the social context in which blind spectators consume SMB . Participant feedback indicated there is a demand for more accessible SMB content such that people can consume SMB by themselves and with their friends. Participants were enthusiastic for a revised system design mixing elements from 3D audio and audio description. We discuss our results in the context of social SMB spectatorship, concluding with insights into accessible SMB technologies. Reference Goncu, C., & Finnegan, D. J. Did you see that!?' Enhancing the Experience of Sports Media Broadcast for Blind People International Federation for Information Processing Technical Committee on Human Computer Interaction ( IFIP TC13 ) Bi-annual International Conference ( INTERACT ) DOI : 10.1007/978-3-030-85623-6_24","tags":"Papers","url":"https://ps2fino.github.io/interact-aug-2021.html","loc":"https://ps2fino.github.io/interact-aug-2021.html"},{"title":"New Publication in ACM Journal of Computing and Cultural Heritage!","text":"We've had a paper accepted in the ACM Journal of Computing and Cultural Heritage special issue on Culture Games! This paper is an analysis of 2 games we made as part of the EU Horizon 2020 UNREST project. We previously wrote (descriptively) about the games, but this paper is a comprehensive study on our installation at the Ruhr Museum, considering reactions from museum visitors and the like. To the best of our knowledge, this paper is the first to discuss what we define as Agonistic Games: serious games which explore the theme of agonism. Here's the abstract: In this paper, we propose Agonistic Games (AGs) as a serious games subcategory that can stimulate critical reflection on topics of dark heritage through multiperspectivity and unsettling play. We first discuss the emerging topic of agonism in memory studies, and then how games can be used to support its objectives. We then discuss the development of 2 original AGs: Endless Blitz and Umschlagplatz ‘43. We explore whether these two AGs were perceived as capable of stimulating critical reflection by collecting data from visitors to the exhibition ‘Krieg. Macht. Sinn' at the Ruhr Museum in Germany where the games were installed, and from participants in an online course describing the games. From analysing data collected, we outline four factors inhibiting the capacity of AGs to stimulate critical reflection (topic, context, design, and assumptions about games) and propose strategies for overcoming these inhibitors. Our findings are valuable to scholars, game researchers, and designers, strengthening the foundations for the design and development of future AGs.investigation to inform the design of effective remote-learning applications. Reference De Angeli, D., Finnegan, D.J., Scott, L., O'Neill, E. Unsettling Play: Perceptions of Agonistic Games . ACM Journal of Computing and Cultural Heritage Special Issue on Culture Games. DOI : 10.1145/3431925 PDF","tags":"Papers","url":"https://ps2fino.github.io/agonistic-games.html","loc":"https://ps2fino.github.io/agonistic-games.html"},{"title":"New Publication in PeerJ Computer Science!","text":"We've had a paper accepted in the PeerJ Open Access journal for Computer Science! Here's the abstract: Massive Open Online Courses are a dominant force in remote-learning yet suffer from persisting problems stemming from lack of commitment and low completion rates. In this initial study we investigate how the use of immersive virtual environments for Power-Point based informational learning may benefit learners and mimic traditional lectures successfully. We examine the role of embodied agent tutors which are frequently implemented within virtual learning environments. We find similar performance on a bespoke knowledge test and metrics for motivation, satisfaction, and engagement by learners in both real and virtual environments, regardless of embodied agent tutor presence. Our results raise questions regarding the viability of using virtual environments for remote-learning paradigms, and we emphasise the need for further investigation to inform the design of effective remote-learning applications. Reference Fitton, I. S., Finnegan, D. J., Proulx, M. J. Immersive virtual environments and embodied agents for e-learning applications . PeerJ Open Access Computer Science DOI : 10.7717/peerj-cs.315 PDF","tags":"Papers","url":"https://ps2fino.github.io/immersive-vles-2020.html","loc":"https://ps2fino.github.io/immersive-vles-2020.html"},{"title":"Invited talk for Wales Tech Week","text":"I presented my talk on Multisensory Perception in Virtual Reality for Wales Tech Week today. Presented virtually via zoom, I discussed research on human perception in VR and how we can develop technologies that adapt and make a better fit for human machine systems. You can catch a video recording the of the presentation here . There were some great questions from an enthusiastic audience. For slides, please check out my previous post from the Pint of Science in 2018.","tags":"Talks","url":"https://ps2fino.github.io/wales-tech-week-2020.html","loc":"https://ps2fino.github.io/wales-tech-week-2020.html"},{"title":"New Publication @ IDC 2020!","text":"We've had a paper accepted to the World's Most Inclusive Participatory Design Workshop @ the ACM Interaction Design & Children conference! Here's the abstract: Game Jams are planned events in which attendees engage in practices of co-creation in an attempt to devise a game concept and prototype. They are designed to be fun, participatory, and stimulate creativity over a short intense period of time. We report on a recent Game Jam, Sacred Spring , aimed at educating children on the medical and scientific history of the Roman Baths in the city of Bath, UK . In this paper, we describe the event and its output, with some brief discussion on what we learned from organizing and running the game jam with a group of children aged 6-9 years old. Our aim is to discuss our Game Jam with the inclusive participatory design ( PD ) community, contextualizing novel game design and game play based learning strategies in the PD space, and devising ways to reach a broader audience in future workshops. My colleague Dr Daniela De Angeli is attending and representing our work. No video this time, but I'll update this post with images from the workshop when I can. Reference De Angeli, D., Finnegan, D. J., Scott, L. Sacred Springs : Teaching Children Local History via a Game Jam. In: Constantin, A., Korte, J.,Wilson, C., Alexandru, C.A., Good, J., Sim, G., Read, J., Fails, J.A., Eriksson, E. (Eds.), Planning the World's Most Inclusive PD Project, ACM Interaction Design and Children ( IDC ) conference 2020. PDF","tags":"Papers","url":"https://ps2fino.github.io/inclusive-pd-2020.html","loc":"https://ps2fino.github.io/inclusive-pd-2020.html"},{"title":"Lancometer — Interactive quizzes in the classroom","text":"Recently, technology for real-time polling of information has become popular to do quick, interactive quizzes for presentations and also as an educational tool in the classroom, for example, tools like MentiMeter and Socrative . Whilst I was intrigued (I'm always looking for ways to engage my students) to the advantages they may offer towards the student experience and learning, I wasn't prepared to change my workflow to fit in to any specific format such technologies may prescribe: I generate HTML presentations using bookdown and don't use PowerPoint for example. I also didn't want to have to download any mobile application or worse, force my students to download anything (A UX nightmare for the classroom!) So over the 2019/20 christmas period, I developed a small web application to facilitate interactive sessions during my lectures. Hosted on the school's OpenStack platform, all I do is simply embed the page in an iframe using knitr and go from there. The students just point their device (phone, laptop, whatever) to a URL or use the generated QR code and they can instantly join (no login/codes required). My web development skills were rusty (haven't really done anything web based since late 2015) so it seemed like a good exercise and christmas was the only time I'd get to do it before the new teaching semester began. Having trialled it in the classroom, here are my initial observations: Students really liked it. Like a lot ! I was skeptical as I've heard the argument where its really just a digital ‘show of hands'. However, it really is more than that. For example, its easier to visualize in a bar chart a show of hands for a set of options rather than go through each in turn. Also, and here's where I think the magic lies and is worth further study, I can see how the show of hands changes over time . I have some ideas for how to study this in an experiment which I'll do at some point. Having my own system means I can discuss the internals of the system: this is useful when teaching a module like CM1202 . Students are also really interested in seeing how things work (especially first years) and I could create a welcoming environment for feedback where they can voice their opinions and suggest new features. Suggestions are one thing but when I can then go and implement their suggestions, and they see this in a future lecture (for example, the ‘Show Answer' utility was something I was unsure about at first but implemented it after an initial pilot at which point a student also thought it would be a good idea), students really appreciate it. Here's a video of Lancometer* in action. * Or perhaps you were looking for this lancometer…","tags":"Technology","url":"https://ps2fino.github.io/lancometer.html","loc":"https://ps2fino.github.io/lancometer.html"},{"title":"Joining Cardiff University","text":"This week I joined the School of Computer Science & Informatics at Cardiff University/Prifysgol Caerdydd. The past week has been a gentle introduction to the School, having completed induction training, I'm looking forward to taking part in the probationary training courses over the coming weeks. I've picked up my staff access card, shifted over my website from Bath, which was painless thanks to pelican and my own custom batch and python scripts, and set up my HR account here at the university. I've also spent the past few days browsing the university's intranet soaking up all the information I can. I'm slowly getting to know the city, and am looking forward to meeting all my new colleagues at the University. Setting my goals for the summer, I'm excited about everything I'm going to learn and teach in my new post and meeting the new 2019/20 cohort of students at Cardiff.","tags":"General Entry","url":"https://ps2fino.github.io/cadiff-may-2019.html","loc":"https://ps2fino.github.io/cadiff-may-2019.html"},{"title":"New Publication @ CHI PLAY 2018!","text":"We've had a publication accepted at CHI PLAY 2018! Here's the abstract: Historical narratives of conflict typically revolve around heroes and villains or perpetrators and victims. However, this dichotomy of events and people into good and evil greatly reduces the extent to which the past can be analysed, explained, and understood. To truly understand the actions that lead to conflict, one must appreciate the dense network of relationships between social agents, each with their own personal motivations and ideals. A contemporary political viewpoint capturing this multiperspectivity is that of Agonism. Focusing on the characters and events, Agonism emphasises the socio-cultural interactions and relationships between all agents involved including bystanders and, crucially, perpetrators. We discuss two ‘Games for a Social Change' that we have developed to promote an Agonistic view: Endless Blitz and Umschlag ‘43 . We describe the games themselves, and the framework of memory studies that informs our work. Here's a demo reel of both Endless Blitz and Umschlagplatz ‘43 in action! Reference De Angeli, D., Finnegan, D. J., Scott, L., Bull, A., O'Neill, E. Agonistic Games: Multiperspective and Unsettling Games for a Social Change. CHI PLAY ‘18 Extended Abstracts. DOI : 10.1145/3270316.3270594 PDF","tags":"Papers","url":"https://ps2fino.github.io/chiplay-2018.html","loc":"https://ps2fino.github.io/chiplay-2018.html"},{"title":"New Publication @ ECCV 2018!","text":"We've had a publication accepted at ECCV 2018! Here's the abstract: This work presents a novel hand pose estimation framework via intermediate dense guidance map supervision. By leveraging the advantage of predicting heat maps of hand joints in detection-based methods, we propose to use dense feature maps through intermediate supervision in a regression-based framework that is not limited to the resolution of the heat map. Our dense feature maps are delicately designed to encode the hand geometry and the spatial relation between local joint and global hand. The proposed framework significantly improves the state-of-the-art in both 2D and 3D on the recent benchmark datasets. Xiaokun Wu wrote up an awesome post on the project on his website . I recommend reading it! They say pictures speak a thousand words, so here's a gif Xiaokun made giving the general idea in a succint way. Reference Wu, X., Finnegan, D. J., O'Neill, E., Yang, Y. HandMap: Robust Hand Pose Estimation via Intermediate Dense Guidance Map Supervision. ECCV 2018: Proceedings of the 15th European Conference on Computer Vision. DOI : 10.1007/978-3-030-01270-0_15 PDF","tags":"Papers","url":"https://ps2fino.github.io/eccv-2018.html","loc":"https://ps2fino.github.io/eccv-2018.html"},{"title":"Invited talk at the Sherborne Science Cafe","text":"Last night I gave a talk at The Sherborne Science Cafe in the beautiful town of Sherborne . It was the biggest audience I've spoken to so far (>> 50 people). The talk was the same talk I gave at this years Pint of Science with some tweaks from feedback after PoS itself. There were many great questions from the audience ranging from the purpose of VR , the ethics of VR and machine intelligence more generally, and of course, ‘When will we have the holodeck!?*'. The science cafe have written a report of the night and put it up on their site which you can check out. For video links, check out my post on the Raven Science Cafe * We already do","tags":"Talks","url":"https://ps2fino.github.io/sherborne-science-cafe-2018.html","loc":"https://ps2fino.github.io/sherborne-science-cafe-2018.html"},{"title":"Avalon board game companion application","text":"The latest version is now available as a free download on the Google Play Store. This past week during the evenings, I wrote a small android application just for fun. It consists of a 3 screen UI for selecting the characters in the game of Avalon . Once selected, it generates the callout for the game, and then begins to speak it back to the players via text-to-speech. Its very rough around the edges (to be fair, I made in a total of about 2.5 working hours over a few days) and contains no accessibility features as of yet. However, some people may find it useful; I know I sure will! Its FOSS using the BSD -3 license . It is available from my Github . Its also Updater compatible.","tags":"Technology","url":"https://ps2fino.github.io/avalon-callout.html","loc":"https://ps2fino.github.io/avalon-callout.html"},{"title":"Updater — A cmake template engine","text":"Today I'm delighted to finally release Updater, a handy little template engine written in python for creating boilerplate project scaffolding code with one click. Updater essentially creates a templated directory structure along with initial CMakeLists.txt files. This helps ensure that the project will always be compilable. Updater grew from an observation I made working with students. As they're still learning how to program, it can be overwhelming for them to ensure their code is well maintained and structured. Using Updater enables them to focus on the implementation task, while giving me some assurance that I will always be able to build the project. Updater is FOSS using the BSD -3 license . It is available from my Github .","tags":"Technology","url":"https://ps2fino.github.io/updater.html","loc":"https://ps2fino.github.io/updater.html"},{"title":"Invited talk @ Pint of Science","text":"I've been invited to talk at Bath's Pint of Science next Month. If you're in Bath and missed my previous talk at The Raven , then why not come and hear v2.0!? I'll be talking about the close relationship between psychology and the technology involved in virtual reality ( VR ), and some of my latest research on perception in VR . You can buy tickets for the event here . Update The night was a success!! Some great questions asked from a curious audience. The event was sold out, and I was delighted to take part this year. I very much hope to do so again next year. Slides are available here . Video links Change blindness Redirected Walking with Change Blindness Haptic Retargeting Showreel of my work","tags":"Talks","url":"https://ps2fino.github.io/pint-of-science-may-2018.html","loc":"https://ps2fino.github.io/pint-of-science-may-2018.html"},{"title":"Invited talk @ CUBRIC","text":"I've been invited to talk at Cardiff's CUBRIC on best programming practices in open science. I'll cover the typeseting language LaTeX and how it can be used in coordination with technology such as ShareLaTeX and Overleaf for collaborative science writing. I'll update this post closer to the time, but the preliminary schedule is up for now . Update The talk was a success! I had a great time; awesome to see so much enthusiasm for open science communication and software tools. I hope I encouraged a few more folks to take the LaTeX plunge and start using it for their research papers. Slides are here .","tags":"Talks","url":"https://ps2fino.github.io/cubric_may_2018.html","loc":"https://ps2fino.github.io/cubric_may_2018.html"},{"title":"Rejected Proposals","text":"There are enough instances of the file drawer problem in academia. A similar notion applies to applications, where we only hear of the successes, perpetuating a hero narrative and brazenly skipping over the missed targets. I don't want to add to that, so I've decided to collate this list of grant/project proposals and applications that have been rejected. Here are my rejections as an anti- CV . Research Council Grant (Co-I) Application not shortlisted Approx. time of submission: June 2020 Mini doctoral training hub ( PI ) Equivalent of 4 PhD students (~ £80k) Application not shortlisted Approx. time of submission: December 2019 XXX mock panel Application rejected before shortlisting Approx. time of submission: December 2019 Lectureship at XXX University Application rejected before interview stage Approx. time of submission: November 2018 XXX Journal Editorial Board Bid for editor role; rejected after EoI submission Approx. time of submission: May 2018 Gamified Employability and Transferable Skills Development Internal TDF bid; rejected after EoI submission Approx. time of submission: February 2018 Amount requested: £15,000","tags":"Grants","url":"https://ps2fino.github.io/rejections.html","loc":"https://ps2fino.github.io/rejections.html"},{"title":"Techspark Feature","text":"I was interviewed for Techspark based on a talk I gave in January . The piece is light and while containing no references to published work (check out my CV page if interested), it does give a fairly accurate portrayal of the kind of work I do. You can read the piece here .","tags":"PR","url":"https://ps2fino.github.io/techspark_march_2018.html","loc":"https://ps2fino.github.io/techspark_march_2018.html"},{"title":"How to solve virtual reality's human perception problem","text":"I wrote a piece for The Conversation on my work in psychophysics. You can read the published article here . Below is the original unedited draft I wrote for those interested. Unedited Article Outside of entertainment, virtual reality ( VR ) has seen significant uptake in more practical domains. For example, using VR to piece together parts of a car engine to test out a look and feel before the manufacturing process. Or to try on the latest fashion accessory before you buy. Our own recent work at Bath has applied VR to exercise; imagine going to the gym to take part in the Tour de France and race against the world's top cyclists. While VR has been successful, it is not without its kinks. Designing an interactive system does not stop at the hardware and software; the human must be factored in too. Perception is the term for how we take information from the world and build understanding from it. Our perception of reality is what we base our decisions on, and mostly determines our sense of presence in an environment . So how to tackle the problem of designing VR systems that really transport us to new worlds with an acceptable sense of presence? As the scale of the problem grows, it becomes difficult to quantify the contribution each element of the experience makes to the person's sense of presence. For example, when watching a 360 film in VR , it is difficult to determine if the on screen animations contribute more or less than the 360 audio technology deployed in the experience. What we need is a method for studying VR in a reductionist manner; removing the clutter then adding piece by piece to observe the effect each has in turn. One theory blends together computer science and psychology: maximum likelihood estimation explains how we combine the information we receive across all our senses, integrating it together to inform our understanding of the environment. In its simplest form, it states that we combine sensory information in an optimal fashion; each sense contributes an estimate of the environment but it is noisy. This scenario is depicted in the figure below which shows how the estimates from our eyes and ears combine to give an optimal estimate somewhere in the middle. Note how the blue curve is slimmer than the other two showing decreased variance; the combined estimate takes the best of both worlds. It is also positioned between the two sensory estimates, showing a compromise of the two. Finally, note it is taller: this corresponds to a higher likelihood in its estimate. This has many applications in VR . Our recent work has applied this to solving a problem in VR with how people estimate distances. Imagine using a driving simulator for teaching people how to drive. If people compress distances in VR , then using it as a learning environment would be inappropriate. Understanding how people integrate information from their senses is crucial to VR because it is not solely visual. Maximum Likelihood Estimation is a tool to model how effectively a VR system needs to render its multisensory environment in order to deliver the desired experience. Understanding perception will lead to more immersive VR experiences. It's not a matter of separating each signal from the noise; it's a matter of taking all signals with the noise to give the most likely result.","tags":"Articles","url":"https://ps2fino.github.io/the_conversation_march_2018.html","loc":"https://ps2fino.github.io/the_conversation_march_2018.html"},{"title":"New Publication @ CHI 2018!","text":"We've had a paper accepted at CHI 2018! Here's the abstract: One of the big challenges today is to keep people healthy through sufficient exercise. In this project we developed a new method for improving exercise performance in a motivating manner using a VR exergame. Players can work out on an exercycle doing high-intensity interval training while wearing a VR headset and racing in a virtual world. Our method is an interactive adaptation of Feedforward, a type of training used to achieve rapid improvements by creating self models showing previously unachieved performance levels. The game lets players compete against themselves, making it a bit harder for them so they are able to surpass their own previous performance. Our method helped players perform better and also have a better experience compared to racing against a virtual competitor. Here's a video of the work, and you can follow the the ReVEaL to see more about what we do. Reference Barathi, S. C., Finnegan, D. J., Farrow, M., Whaley, A., Heath, P., Buckley, J., Dowrick, P. W., Wünsche, B. C., Bilzon, J. L. J., O'Neill, E. & Lutteroth, C. Interactive Feedforward for Improving Performance and Maintaining Intrinsic Motivation in VR Exergaming. CHI 18': Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. DOI : 10.1145/3173574.3173982 PDF","tags":"Papers","url":"https://ps2fino.github.io/chi-2018.html","loc":"https://ps2fino.github.io/chi-2018.html"},{"title":"Bath Science Cafe @ The Raven","text":"Last night I gave a talk at The Raven in town as part of the Bath Science Cafe . I was thrilled to be invited!! My talk discussed how understanding perception can help to design virtual worlds that appear fluid and immersive. I covered elements such as redirected walking and foveated rendering emphasising how both techniques take advantage of human perception and deliver experiences that maintain quality while significantly reducing constraints around physical space and computational power. I ended the talk with my own work on designing incongruent audiovisual environments to reduce issues with distance and scale perception in VR . The talk was well received, and I hope to deliver it again someday! Slides Slides are available here Video links Change blindness Unlimited Corridor Redirected Walking with Change Blindness Plausibility Illusion","tags":"Talks","url":"https://ps2fino.github.io/bath_science_cafe.html","loc":"https://ps2fino.github.io/bath_science_cafe.html"},{"title":"EngD = Done!","text":"Update A copy of my thesis is now available from my cv page . Today I successfully defended my thesis Compensating for Distance Compression in Virtual Audiovisual Environments, passing my viva voce with minor corrections! Once my corrections have been completed and submitted, I'll stick a PDF up here for anyone who might be interested. The past 4 years have been a whirlwind, as I've written about previously and I have learned so much. Thanks go to my academic advisors, Prof. Eamonn O'Neill & Dr. Michael Proulx who have mentored me through the years, teaching me lessons I can't even describe in words. Thanks also to Rob McHardy, my industrial advisor, who helped hone my software skills further from my BSc days into my EngD. Thanks also to the myriad of people I have interacted with over the years; each of you has influenced my thinking in a variety of different ways. Its been one hell of a journey. Celebrating the end of my EngD over the coming days, I look forward to my career. Now that I have my license, I'm excied over future prospects and the projects I will get my teeth stuck into!","tags":"General Entry","url":"https://ps2fino.github.io/engd_complete.html","loc":"https://ps2fino.github.io/engd_complete.html"},{"title":"New paper accepted into SIVE 2017!","text":"My paper titled \"An Approach to Reducing Distance Compression in Audiovisual Virtual Environments\" has been accepted into the SIVE (Sonic Interactions in Virtual Environments) workshop as part of IEEE VR 2017 ! I will be presenting my paper and it will be published as part of the conference proceedings. See you in LA ! Reference Finnegan, D. J., O'Neill, E., & Proulx, M. J. An approach to reducing distance compression in audiovisual virtual environments. In Sonic Interactions for Virtual Environments ( SIVE ), 2017 IEEE 3rd VR Workshop on (pp. 1-6). IEEE . DOI : 10.1109/ SIVE .2017.7901607 PDF","tags":"Papers","url":"https://ps2fino.github.io/sive-ieeevr-2017.html","loc":"https://ps2fino.github.io/sive-ieeevr-2017.html"},{"title":"Research, Anxiety, and Overcoming it all through Applied Psychology","text":"I've started to reflect on my EngD, thinking about the PhD Journey as a whole, and the people I've interacted with over the past 4 years. I've experienced the ups and downs, the observed PhD curve and I've grown a lot. The biggest thing I've learned though, over the past 4 years, is about research attitudes. Knowing that there are unknown unknowns and having the humility to accept that. When I began my research, I felt overwhelmed: I tried and tried to review fields and areas where ‘more research was needed' to no avail. I became frustrated, anxious, and felt hopelessly lost in a sea of ‘potential areas of interest' and began questioning my own ability. Not from the healthy perspective; questions like \"Am I right?\" Or \"What if there is another way?\" These are good questions, and fall under my \"humility\" heading. Instead, I was asking \"Can I do this?\" and \"How do I know where to begin?\" I recently completed an application for an RA position at Bath , and when I was writing my personal statement, I thought about my own approach to my research and realised that an interesting theory applied…. The Big Five How would you describe personality? Sure, you can to great lengths, with use of colorful adjectives and poetic prose to describe personality. This is great if you're writing a book, or a reference for someone, but scientifically its way too much. Its difficult to compare and discuss personalities from a scientific point of view with such a high dimensionality or degrees of freedom . Rather, some clever psychologists attempted to reduce this dimensionality to a set of 5 core traits, and claimed that personality can be described by plotting across these five dimensions. Sometimes called the OCEAN model (scientists love acronyms, especially when those acronyms equate to actual words with ambigiously related semantics to what the acronym itself represents), it is widely applicable to many domains, and is useful as a measurement tool of personality. Once you can measure something, you can cluster data into categories, and then develop around these clusters. From a HCI perspective, one of the most novel applications I've come across of the OCEAN theory is the thory applied to gamers (i.e people who play games often). Jason Vandenburghe gave a talk at the 2014 CHIPlay conference in Toronto. Sadly I wasn't at the talk, but I'd seen Vandenburghe's earlier GDC talk in 2012. Vandenburghe applies OCEAN as a way of modelling player behaviour and their expectations from a game. The gist is that, if you can identify personality traits of players, for example those who are more open to exploration versus those who are more introverted, perhaps less keen on direct competition, you can adjust the game mechanics and dynamics to suit that player. Obviously, this is of direct interest to the games industry, and is useful for game designers to take into consideration. In my personal statement, I applied OCEAN to a PhD candidate, explaining the sides of the spectrum I feel a good candidate would lie. You can read my statement here , but I'll elaborate on my choices here. I've also kept them discipline agnostic; while I'm sure this can be further refined to fit specific disciplines (a model is a model though; always be weary of overfitting ), I've opted to keep things general. These are qualities of traits I feel any PhD student should possess. An OCEAN PhD I guess at this point, I should probably elaborate a bit on the OCEAN dimensions. The first, Openness relates to a person's apetite for new experiences. Rather than sticking to what works, a good PhD candidate is someone who embraces new opportunities and experiences, open to failure and a tenacity to take risks. A PhD is ultimately about learning how to deal with failure. All the paper rejections, deadlines missed for various reasons, and feelings of complete inability to complete anything is part of the learning process. My advisor said to me \"There'll always be another deadline\". It took me a while to fully appreciate the gravity of that sentence. It wasn't just to pick me up, but to really drill home the notion of research as an endless cycle. There will always be unknown unknowns, therefore there'll always be more research to do. If theres always more research to do, there'll always be another conference venue or journal deadline. The second trait is Conscientousness. This relates to ones ability to be resourceful and self sustainable. Professor Philip Willis once sent a departmental email around about how in the US they use the term PhD ‘advisor' rather than the term used in the UK and Ireland, ‘supervisor'. This stuck with me as I really saw it as a more appropriate term. A PhD should not require supervision; when you apply for a PhD in computer graphics, I would assume you have working knowledge of vector math and some experience with practical rendering techniques in theory and code. The same applies for any discipline be it music, geography, history, politics. The point is that this is already assumed: I would expect you to be capable of studying and working without supervision. However, at time what you will need is guidance. You may strike a mental wall in your research. Advice in the form of guidance is more effective here, perhaps suggesting related avenues that you may have overlooked, or indirect research areas that, with a bit of creative thinking, may lead to breakthrough methods just waiting to be applied to your research. Up next is Extraversion. A PhD student needs to be extraverted. Gone are the days of solo PhD theses; massive texts stuffed full of secluded work done in a lab or an office over the course of 3 years. The world has shifted, with globalisation catapulting us into the age of fast communication of ideas, and an ever expanding space of research domains opening up. Its impossible to do good research alone. Yes, I understand that a PhD is your work, but that work is done in a context of people, other disciplines, and more and more information on a daily basis. Some people even consider doing a PhD is irrelevant . My point here is that, tying in with Openness, a good PhD is someone who embraces methods and approaches from related research fields, and adopts an extraverted mind in approaching skill development. Complex problems in your field may only be complex because the right tools either do not exist, or do exist, but are applied in other disciplines where they also are approriate. Be adventurous! Agreeablenss is an interesting one, as a good PhD is somewhere in the middle. You should agree with data that opposes your initial hypotheses and beliefs, as painful as it may be to swallow. However, this does not mean you do so blindly. Ask why this data is the way it is? What does it mean for your hypothesis? Is it wrong, or just misguided? How can you learn from it? What if your hypothesis was originally based upon previous studies, a la Bayes Theorem ? Following Bayes logic, new information should not alter your view so much if you already have a substantial background in the opposing direction. The point here is to take in this new information, reflect on it, and then feed it back in to your new thinking. Finally, we have Neuroticism. I'm not saying a good PhD is a never neurotic; you'd have to be a sociopath to not feel upset at times during the course of your PhD. However, it is important to constantly reflect on your situation and understand that it is a bump in the road, not a road block. Remain calm in the face of opposition. Rather than a fit of hysteria, react to oppposition in a way that is productive. Process it, then fire some questions back at it. Don't take it at face value, but rather assimilate it and refine it. You may find that what was initially the polar opposite may actually only have issue with certain aspects of your standpoint. Be dynamic and invite opposition. It'll make your PhD richer in the end.","tags":"General Entry","url":"https://ps2fino.github.io/next-steps.html","loc":"https://ps2fino.github.io/next-steps.html"},{"title":"The Simpsons & their Mathematical Secrets","text":"I recently finished reading Simon Singh ‘s book titled ‘The Simpsons & their Mathematical Secrets' and thought I'd write a review as it was a riveting literary account of the history of mathematics, as told through personal interviews with the writing team of both ‘The Simpsons' & ‘Futurama'. The book does not demand extensive knowledge nor professional ability and grasp at Mathematics; instead it actually illuminates some of the more difficult problems, translating them into understandable language. Synopsis The book details how ‘The Simpsons' has spent the past 3 decades sneakily including some nontrivial mathematics within its episodes; the reason seemingly being that the writers felt it was humourous and would engage the more mathematically inclined viewers. Singh talks about how some episodes contain what is known as ‘Freeze Frame' gags, where the visual joke appears for less than 5 frames, forcing interested parties to pause the video playback to view it. However, other episodes place the maths in full view of the audience, in what appears to be random numbers or equations. However, upon further investigation it can be shown that the symbols and equations in episodes are far from meaningless combinations. One of my personal favorites is as Singh describes an episode of ‘Futurama' where Bender, a talking, drunken android protagonist sees a random binary sequency written in blood. Paying homage to that scene in Stanley Kubrick's The Shining', He then sees the reversed sequence through a mirror and is horrified!! Only those with some knowledge of binary number representation would appreciate this joke; read the book to find out more! Singh introduces many famous figures in the world of mathematics throughout the book. He spans centuries of history, from Archimedes to Euler , from Gauss to Germain , and right up to Ramanujan and Erdős (he even throws in a reference to Bill Gates of Microsoft fame and his one and only published academic paper). Some chapters are dedicated to individual mathematicians, using their achievements as a narrative, and introducing some of the problems they commited their lives too. With each new mathematician, Singh demonstrates his ability for morphing mathematics from what can be (for most people I presume) a difficult thing to understand into intuitive, clear and sometimes beautiful explanations about one of the worlds truly fascinating subjects. Engagement The book reignited an old passion in me for mathematics. Having strayed from the discipline for quite some time (I developed a paralyzing fear of maths during my undergraduate studies at University after having loved the subject and performed reasonably well during highschool), I found Singh to phrase the theorems in the book in such a way that they weren't terrifying any longer. Instead, the mathematics is juxtaposed with music, paintings, and other forms of art. It is clear from the outset that Singh believed mathematics deserves a place in this exclusive domain and does in fact state this explicitly though a quote from Keith Devlin regarding the degree to which Euler's equation reaches into the ‘very depths of existence'. Singh cleverly strays from deep technical derivations of some of the more complex topics within the main body of the book, opting to include them as appendices at the end. This avoids a context switch from consuming some fascinating history to remembering group theory, fractals, and prime numbers. This fits every reader from the casually piqued to the mathematics finatics obsessed with the underlying theory to satisfy their thirst for some proofs. After all, this book is really more of a historical passage through the catacombs of modern mathematics as opposed to a university freshman textbook on linear algebra. I found the book grossly engaging; I couldn't put it down and gorged upon its satisfactory ~250 pages in a weekend. Verdict I really enjoyed the book (as I imagine is quite obvious from my excited tone). Not only did I enjoy reading about the people behind the shows, my view of the Simpsons as a ‘dumb' tv show has been radically altered. I have developed a new found appreciation for it (indeed, I'll be looking for some Freeze Frame gags myself over the next few months in re-runs!), and also some of the issues I've had with mathematics since my undergraduate years have been lifted. I feel more confident and open to reading about mathematics again. In a way this book has truly illuminated my bleak view on the subject. What more can I say other than; GO READ IT ! :-)","tags":"Book Reviews","url":"https://ps2fino.github.io/simpsons-maths.html","loc":"https://ps2fino.github.io/simpsons-maths.html"},{"title":"Rendering spatial audio on a desktop: The SSR and APF libraries","text":"I've been playing around with the SSR library in order to render a binaural soundscape for a project I'm working on. Whilst a great library, I struggled to get to grips with it for a few days. The library makes heavy use of templates (a powerful paradigm of C++ but can be awkward to read) and is written using some design patterns I had never encountered before. I started by reading some of the source code, trying to compile the header-only library and get some test code working. After spending hours getting the library to compile, I was ready to try it out with some sample assets from Audio Defence . Compiler errors began to arise upon simply instantiating the ssr::BinauralRenderer so I had to dig a little deeper. I had a read of the source code and I came across some examples that were included in the repository. I also emailed one of the author's of the library to ask for some help with integrating the SSR as a library into my existing framework in order to handle the binaural rendering. After a week of bashing my head against the wall, I've now managed to pump out some spatial sound from the renderer, sending it out to the speakers and dumping it to a stereo file. I've decided to jot down some notes here to help me remember how the thing works!! The ssr::BinauralRenderer is a subclass of the apf::MimoProcessor, which is an abstract multiple input/multiple output processor that enables the programmer to implement the processing callback while handling the threading and access control of the samples held in the processor's buffer. The renderer is instantiated by passing a apf::paramter_map instance which is a key-value dictionary of configuration settings for the renderer. The main settings required are the sample rate, block size and the location (full path) to the HRIR file that contains the impulse responses for convoluion. The processor functions through use of the Policy Design Pattern . This design pattern dictates that a can have a number of different policies for responding to similar situations (ie. a class may have a number of different policies regarding the printing of data to a file or to a TCP stream). In my case, the policies that the renderer is concerned with are its interface (how to process it's data buffers at each audio cycle or rather how to ‘use' and interface with it) and how to act in a threaded manner. To specify which policies to use, you simply include the header file of the policy and define a macro called APF_MIMOPROCESSOR_INTERFACE_POLICY for the interface policy and APF_MIMOPROCESSOR_THREAD_POLICY for the thread policy. The library comes with a default thread header which just uses a single threaded policy (ie. not implemented) on windows and the POSIX library for *nix and OSX systems. In order to use the binaural rendererer, you need to specify the policies you want to use. The renderer relies on two policies in it's implementation; an interface policy and a threading policy. To use the renderer as a standalone module, the pointer policy must be used. This then opens up the audioCallback function to be called manually by the application programmer when they want to process some data. The function accepts 3 arguments, the block size of the frame to be processed, a pointer to a series of inputs and a pointer to a pair of outputs (as the binaural renderer is an instance of an N-input, 2-output processor for stereo binaural output). The processor requires it's input to be a pointer to a list of channels. These channels can be implemented as a series of vectors. The renderer's output is also expected to be a series of vectors representing the audio channels. The inputs should be a N * BLOCK_SIZE matrix where BLOCK_SIZE is the number of frames to be processed as a block during each run of the audio cycle. The N is the number of channels in the input. The outputs should be a 2 * BLOCK_SIZE matrix, indicating stereo output. The renderer expects a 1-1 mapping of input channels to sources, and the sources are ordered with the channels (ie Channels[0] is the first source, Channels[1] the second etc…) Finally, for dumping to a file, you need to transpose the channels as libsndfile reads in row-wise order, intereleaving the channels as it dumps to the file. This was the major source of confusion for me and it took some fiddling and multiple reads of the source repo to understand how that worked. So to recap; the binaural renderer can be instantiated after specifying the policies required to do it's thing. Next you need to generate a parameter map, a key-value dictionary containing the configuration (block size, HRIR file path etc.) for the renderer. In order to use the renderer, you pass a pointer to a list of arrays representing the channels of the audio (best to use the apf::fixed_matrix container that comes with the APF framework). A blunder was in dumping the output to a file; this wasn't the SSR 's fault as libsndfile expects reads and writes in row wise order for (de)interleaving. All I had to do here is have a second output buffer which is the transposed matrix of the output list of channels. You can then call the writef() function of the SndFileHandle object in the libsndfile C++ API for writing stereo output to the file. Having figured all of this out I can finally move onto the image processing aspect of my project. More on this to come later.","tags":"Technology","url":"https://ps2fino.github.io/ssr.html","loc":"https://ps2fino.github.io/ssr.html"},{"title":"Auditory saliency and its role in accessible gaming","text":"Today I met with my supervisors to discuss my upcoming transfer viva and interesting topics for studies moving into 2015. While nearing completion, my supervisors gave some valuable feedback for the tone and message of my report; especially the necessity of a coherent narrative. I've tried to be as thorough as possible in my report writing but I need to make sure that the reason for reading it is conveyed clearly to the reader. After discussing the report we moved on to the interesting stuff; what to start working on next. The overarching theme of my thesis is inclusive gaming. By this, I am interested in design techniques and technologies that can enable games to reach a wider audience by becoming artefacts of an accessible design. How can an interface surpass the status quo and becoming \"accessible\" whilst maintaining the same level of efficiency as one for sighted players? Given that our aural senses have a much smaller capacity for interpreting information when compared to our visual sense, this sounds like it is unachievable. However, a lot of the information our visual sense perceives in the occipital lobe and propogates through the visual cortex is redundant, irrelevant. Most of the time, there is a subset of the data perceived that is of interest or rather necessary to understand the scene which we are observing. In other words, what we want is salience. Whilst current accessible tools focus on mapping visual elements 1-1 to an equal yet slower modality (temporality issues exist in screen readers and text-to-speech systems), might there be a way to extract the information in a visual scene, remove non-salient information and then compress it into a form that enables a ~1:1 mapping of the objects in the scene and the sounds used to represent them? Back to the books for me. Below are references shared with me by my supervisor. Passing them on here. Auditory Salience Crossmodal Correspondences","tags":"General Entry","url":"https://ps2fino.github.io/saliency.html","loc":"https://ps2fino.github.io/saliency.html"},{"title":"First Post","text":"So, I set up this site almost a year ago now and never actually published anything to it. I've decided to have a bash at it and might try and publish to it at least once a week, probably on a Sunday afternoon ( much like this one :-) ). I've often tried blogging in the past but could never quite do it. I've found it uncomfortable, difficult or frustrating in the past to write things down in a public format as I've always kept notes in the past. I've been thinking however that this maintaining a blog might be a good idea for my EngD as it will certainly help build up a corpus of writing which may prove useful in two years time when it comes to the viva. This past year has seen a lot happen in my academic life. Highlights include: UBISS Taking part in the 5th UBI Summer School in Oulu (link UBISS ), where my team took home the best project award from Workshop D. The workshop was given by Dr. Floyd Mueller from RMIT in Melbourne, Australia. The workshop involved exploring the design of physical based games that incorporate digital technology in some form. Dr. Mueller has a nicer terminology; ‘Bodily Play'. The school proved an indispensable week full of activities from learning interesting research in physical gaming as well as meeting many students from around the world studying STEM disciplines. The best part was that the game I created with my team, Reindeer & Wolves, was published as a short paper at the CHI PLAY conference in Toronto. There is a QR code at the bottom of this page with a DOI embedded for the article. Audio Defence Winning the accessibility award at the TIGA Games Industry Awards in London. The ceremony took place in November and a game I have worked on the past year with my partner company, Somethin' Else , won the Accessibility award. We were delighted to have won the award in recognition of the work we've been doing over the past year. The game is a first person shooter where the enemies (or shoot-ies) are rendered binaurally for a 3D spatial effect in real time. The game is available on the App Store here . As I approach the end of the year, I am prepping for my transfer report and viva. This I hope will go smoothly as I want to demonstrate the work I've done so far as well as pose a structured plan for the next 2 years. I'll write my next post next week. So for now, I'm signing off.","tags":"General Entry","url":"https://ps2fino.github.io/first-post.html","loc":"https://ps2fino.github.io/first-post.html"}]}